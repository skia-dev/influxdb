[write]
  concurrency = 10
  batch_size = 5000
  batch_interval = "0s"
  database = "stress"
  precision = "n"
  address = "localhost:8086"
  reset_database = true
  # works, but dont use it
  starting_point = 3 # how far back in time to go in weeks

[[series]]
  point_count = 1000 # number of points that will be written for each of the series
  measurement = "cpu"
  series_count = 10000

 # tag_count = 20 # number of "generic" tags on a series (e.g. tag-key-1=tag-value, ... ,tag-key-20=tag-value)

  [[series.tag]]
    key = "host"
    value = "idk"

  [[series.tag]]
    key = "location"
    value = "lame"

  [[series.field]]
    key = "value"
    type = "float64"

  [[series.field]]
    key = "percent"
    type = "int"

  [[series.field]]
    key = "idk"
    type = "bool"

  [[series.field]]
    key = "default"

[[series]]
  point_count = 100 # number of points that will be written for each of the series
  measurement = "mem"
  series_count = 100000

  [[series.tag]]
    key = "host"
    value = "idk"

  [[series.tag]]
    key = "location"
    value = "lame"

  [[series.field]]
    key = "value"
    type = "float64"

  [[series.field]]
    key = "loc"
    type = "float64"

  [[series.field]]
    key = "sunny"
    type = "bool"

  [[series.field]]
    key = "idk"
    type = "int"

[measurement_query] # SELECT aggregates(values) FROM measurements WHERE tag-key='tag-values-1' extras
  enabled = true
  concurrency = 10
  aggregates = ["mean", "count"]
  fields = ["value"]
  extras = "GROUP BY time(1h)"
  interval = "500ms"

[series_query] # SELECT aggregates(values) FROM measurements WHERE time > current_timespan extras
  enabled = true
  concurrency = 10
  aggregates = ["mean", "count"]
  fields = ["value"]
  extras = "GROUP BY time(1h)"
  timespan = "5m"
  interval = "50ms"
